{
 "nbformat": 4,
 "nbformat_minor": 2,
 "metadata": {
  "language_info": {
   "name": "python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "version": "3.6.9-final"
  },
  "orig_nbformat": 2,
  "file_extension": ".py",
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "kernelspec": {
   "name": "python36964bitnnenvvenv7777d63c30c243ed83171a0c6aa28fa8",
   "display_name": "Python 3.6.9 64-bit ('nn_env': venv)"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "   Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n0            6      148             72             35        0  33.6   \n1            1       85             66             29        0  26.6   \n2            8      183             64              0        0  23.3   \n3            1       89             66             23       94  28.1   \n4            0      137             40             35      168  43.1   \n\n   DiabetesPedigreeFunction  Age  Outcome  \n0                     0.627   50        1  \n1                     0.351   31        0  \n2                     0.672   32        1  \n3                     0.167   21        0  \n4                     2.288   33        1  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Pregnancies</th>\n      <th>Glucose</th>\n      <th>BloodPressure</th>\n      <th>SkinThickness</th>\n      <th>Insulin</th>\n      <th>BMI</th>\n      <th>DiabetesPedigreeFunction</th>\n      <th>Age</th>\n      <th>Outcome</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>6</td>\n      <td>148</td>\n      <td>72</td>\n      <td>35</td>\n      <td>0</td>\n      <td>33.6</td>\n      <td>0.627</td>\n      <td>50</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>85</td>\n      <td>66</td>\n      <td>29</td>\n      <td>0</td>\n      <td>26.6</td>\n      <td>0.351</td>\n      <td>31</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>8</td>\n      <td>183</td>\n      <td>64</td>\n      <td>0</td>\n      <td>0</td>\n      <td>23.3</td>\n      <td>0.672</td>\n      <td>32</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>89</td>\n      <td>66</td>\n      <td>23</td>\n      <td>94</td>\n      <td>28.1</td>\n      <td>0.167</td>\n      <td>21</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>137</td>\n      <td>40</td>\n      <td>35</td>\n      <td>168</td>\n      <td>43.1</td>\n      <td>2.288</td>\n      <td>33</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "\n",
    "seed = 42\n",
    "np.random.seed(seed)\n",
    "df = pd.read_csv('./diabetes.csv')\n",
    "df.head()\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI', 'DiabetesPedigreeFunction', 'Age']\n(614, 8)\n(154, 8)\n"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "features = list(df.columns.values)\n",
    "features.remove('Outcome')\n",
    "print(features)\n",
    "X = df[features]\n",
    "y = df['Outcome']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "field Glucose: num 0-entries: 5\nfield BloodPressure: num 0-entries: 35\nfield SkinThickness: num 0-entries: 227\nfield Insulin: num 0-entries: 374\nfield BMI: num 0-entries: 11\nField: Glucose; fixed 5 entries with value: 121.687\nField: BloodPressure; fixed 35 entries with value: 72.405\nField: SkinThickness; fixed 227 entries with value: 29.153\nField: Insulin; fixed 374 entries with value: 155.548\nField: BMI; fixed 11 entries with value: 32.457\nfield Glucose: num 0-entries: 0\nfield BloodPressure: num 0-entries: 0\nfield SkinThickness: num 0-entries: 0\nfield Insulin: num 0-entries: 0\nfield BMI: num 0-entries: 0\n"
    }
   ],
   "source": [
    "zero_fields = ['Glucose', 'BloodPressure', 'SkinThickness', 'Insulin', 'BMI']\n",
    "\n",
    "def check_zero_entries(data, fields):\n",
    "    \"\"\" List number of 0-entries in each of the given fields\"\"\"\n",
    "    for field in fields:\n",
    "        print('field %s: num 0-entries: %d' % (field, len(data.loc[ data[field] == 0, field ])))\n",
    "\n",
    "check_zero_entries(df, zero_fields)\n",
    "\n",
    "def impute_zero_field(data, field):\n",
    "    nonzero_vals = data.loc[data[field] != 0, field]\n",
    "    avg = np.sum(nonzero_vals) / len(nonzero_vals)\n",
    "    k = len(data.loc[ data[field] == 0, field])   # num of 0-entries\n",
    "    data.loc[ data[field] == 0, field ] = avg\n",
    "    print('Field: %s; fixed %d entries with value: %.3f' % (field, k, avg))\n",
    "\n",
    "for field in zero_fields:\n",
    "    impute_zero_field(df, field)\n",
    "\n",
    "check_zero_entries(df, zero_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend",
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Starting training...\nWARNING:tensorflow:The `nb_epoch` argument in `fit` has been renamed `epochs`.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\nWARNING:tensorflow:Can save best model only with val_acc available, skipping.\n"
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-6561dbf63c94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     34\u001b[0m                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m                     verbose=0)\n\u001b[0m",
      "\u001b[0;32m~/Desktop/neural-net/nn_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    817\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    818\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 819\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    820\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m~/Desktop/neural-net/nn_env/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m                 \u001b[0meval_data_iter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initializer\u001b[0m  \u001b[0;31m# pylint: disable=pointless-statement\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m               \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m                 \u001b[0meval_data_iter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m               validation_callbacks = cbks.configure_callbacks(\n",
      "\u001b[0;32m~/Desktop/neural-net/nn_env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    416\u001b[0m     if (context.executing_eagerly()\n\u001b[1;32m    417\u001b[0m         or ops.get_default_graph()._building_function):  # pylint: disable=protected-access\n\u001b[0;32m--> 418\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0miterator_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOwnedIterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    419\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    420\u001b[0m       raise RuntimeError(\"__iter__() is only supported inside of tf.function \"\n",
      "\u001b[0;32m~/Desktop/neural-net/nn_env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, dataset, components, element_spec)\u001b[0m\n\u001b[1;32m    592\u001b[0m           context.context().device_spec.device_type != \"CPU\"):\n\u001b[1;32m    593\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/cpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 594\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    595\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    596\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/neural-net/nn_env/lib/python3.6/site-packages/tensorflow_core/python/data/ops/iterator_ops.py\u001b[0m in \u001b[0;36m_create_iterator\u001b[0;34m(self, dataset)\u001b[0m\n\u001b[1;32m    617\u001b[0m               \u001b[0moutput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flat_output_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    618\u001b[0m               output_shapes=self._flat_output_shapes))\n\u001b[0;32m--> 619\u001b[0;31m       \u001b[0mgen_dataset_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mds_variant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterator_resource\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    620\u001b[0m       \u001b[0;31m# Delete the resource when this object is deleted\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m       self._resource_deleter = IteratorResourceDeleter(\n",
      "\u001b[0;32m~/Desktop/neural-net/nn_env/lib/python3.6/site-packages/tensorflow_core/python/ops/gen_dataset_ops.py\u001b[0m in \u001b[0;36mmake_iterator\u001b[0;34m(dataset, iterator, name)\u001b[0m\n\u001b[1;32m   2694\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[1;32m   2695\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtld\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MakeIterator\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2696\u001b[0;31m         tld.op_callbacks, dataset, iterator)\n\u001b[0m\u001b[1;32m   2697\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2698\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "NB_EPOCHS = 500  # num of epochs to test for\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "## Create our model\n",
    "model = Sequential()\n",
    "\n",
    "# 1st layer: input_dim=8, 12 nodes, RELU\n",
    "model.add(Dense(12, input_dim=8,  activation='relu'))\n",
    "# 2nd layer: 8 nodes, RELU\n",
    "model.add(Dense(8,  activation='relu'))\n",
    "# output layer: dim=1, activation sigmoid\n",
    "model.add(Dense(1,  activation='sigmoid' ))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='binary_crossentropy',   # since we are predicting 0/1\n",
    "             optimizer='adam',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "# checkpoint: store the best model\n",
    "# ckpt_model = 'pima-weights.best.hdf5'\n",
    "# checkpoint = ModelCheckpoint(ckpt_model, \n",
    "#                             monitor='val_acc',\n",
    "#                             verbose=1,\n",
    "#                             save_best_only=True,\n",
    "#                             mode='max')\n",
    "# callbacks_list = [checkpoint]\n",
    "\n",
    "print('Starting training...')\n",
    "# train the model, store the results for plotting\n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    validation_data=(X_test, y_test),\n",
    "                    epochs=NB_EPOCHS,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    # callbacks=callbacks_list,\n",
    "                    verbose=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}